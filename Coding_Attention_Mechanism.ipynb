{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5bed801",
   "metadata": {},
   "source": [
    "**A simple self-attention mechanism without trainable weights**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f52f04e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "inputs = torch.tensor(\n",
    "  [[0.43, 0.15, 0.89], # Your     (x^1)\n",
    "   [0.55, 0.87, 0.66], # journey  (x^2)\n",
    "   [0.57, 0.85, 0.64], # starts   (x^3)\n",
    "   [0.22, 0.58, 0.33], # with     (x^4)\n",
    "   [0.77, 0.25, 0.10], # one      (x^5)\n",
    "   [0.05, 0.80, 0.55]] # step     (x^6)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68b86062",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.5500, 0.8700, 0.6600])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_query = inputs[1]\n",
    "input_query "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0beb321b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.4300, 0.1500, 0.8900])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_1 = inputs[0]\n",
    "input_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb07bee0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9544)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.dot(input_query, input_1) #dot product calculates the similarity between the query and the key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6fd0dda0",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = inputs[1] #2nd input is taken as example and this is called as query\n",
    "\n",
    "attn_scores_2 = torch.empty(inputs.shape[0]) #empty tensor is created to store the attention score of the query token\n",
    "\n",
    "for i, x_i in enumerate(inputs): #enumerate function is used to get the index and the value of the input tensor\n",
    "    attn_scores_2[i] = torch.dot(query, x_i) #dot product is calculated between the query and the key (key refers to other tokens including the query token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b2e6b947",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.9544, 1.4950, 1.4754, 0.8434, 0.7070, 1.0865])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn_scores_2 #this is the attention score of the query token attention scores refers to the similarity between the query and the key if you see the query token is most similar to the query token itself that is why it is the highest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "85f2d533",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1385, 0.2379, 0.2333, 0.1240, 0.1082, 0.1581])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn_weights_2 = torch.nn.functional.softmax(attn_scores_2, dim=0) #softmax is applied to the attention scores to get the attention weights\n",
    "attn_weights_2 #this is the attention weight of the query token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f0999fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#now we will calculate the context vector of the query token which is the weighted sum of the input tokens with this attention weights\n",
    "\n",
    "query = inputs[1]\n",
    "\n",
    "context_vec_2 = torch.zeros(query.shape) #empty tensor is created to store the context vector of the query token and the shape of the context vector is the same as the query token\n",
    "\n",
    "for i, x_i in enumerate(inputs): #enumerate function is used to get the index and the value of the input tensor\n",
    "    context_vec_2 += attn_weights_2[i] * x_i #weighted sum is calculated between the attention weights and the input tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "71492bde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.4419, 0.6515, 0.5683])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_vec_2 #this is the context vector of the query token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8c5aff9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "attn_scores = torch.zeros(6,6) #empty tensor is created to store the attention scores of the all the token with respect to all the other tokens so it's a 6x6 matrix\n",
    "\n",
    "for i, x_i in enumerate(inputs): #enumerate function is used to get the index and the value of the input tensor\n",
    "    for j, x_j in enumerate(inputs): #enumerate function is used to get the index and the value of the input tensor\n",
    "        attn_scores[i, j] = torch.dot(x_i, x_j) #dot product is calculated between the input tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "50d4662f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9995, 0.9544, 0.9422, 0.4753, 0.4576, 0.6310],\n",
       "        [0.9544, 1.4950, 1.4754, 0.8434, 0.7070, 1.0865],\n",
       "        [0.9422, 1.4754, 1.4570, 0.8296, 0.7154, 1.0605],\n",
       "        [0.4753, 0.8434, 0.8296, 0.4937, 0.3474, 0.6565],\n",
       "        [0.4576, 0.7070, 0.7154, 0.3474, 0.6654, 0.2935],\n",
       "        [0.6310, 1.0865, 1.0605, 0.6565, 0.2935, 0.9450]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn_scores #if you look at this you will see that attn_scores_2 is the second row of this matrix so each row is the attention score of that token with respect to all the other tokens and the diagonal elements are the attention scores of the query token with respect to itself which is the highest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5302d9c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9995, 0.9544, 0.9422, 0.4753, 0.4576, 0.6310],\n",
       "        [0.9544, 1.4950, 1.4754, 0.8434, 0.7070, 1.0865],\n",
       "        [0.9422, 1.4754, 1.4570, 0.8296, 0.7154, 1.0605],\n",
       "        [0.4753, 0.8434, 0.8296, 0.4937, 0.3474, 0.6565],\n",
       "        [0.4576, 0.7070, 0.7154, 0.3474, 0.6654, 0.2935],\n",
       "        [0.6310, 1.0865, 1.0605, 0.6565, 0.2935, 0.9450]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn_scores = inputs @ inputs.T #this is the same as the above code but it is more efficient and it is a matrix multiplication\n",
    "attn_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "206e0d5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2098, 0.2006, 0.1981, 0.1242, 0.1220, 0.1452],\n",
       "        [0.1385, 0.2379, 0.2333, 0.1240, 0.1082, 0.1581],\n",
       "        [0.1390, 0.2369, 0.2326, 0.1242, 0.1108, 0.1565],\n",
       "        [0.1435, 0.2074, 0.2046, 0.1462, 0.1263, 0.1720],\n",
       "        [0.1526, 0.1958, 0.1975, 0.1367, 0.1879, 0.1295],\n",
       "        [0.1385, 0.2184, 0.2128, 0.1420, 0.0988, 0.1896]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn_weights = torch.softmax(attn_scores, dim=1) #softmax is applied to the attention scores to get the attention weights dim=1 means that the softmax is applied to each row of the matrix so each row adds up to 1\n",
    "\n",
    "attn_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a0cb141",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4421, 0.5931, 0.5790],\n",
       "        [0.4419, 0.6515, 0.5683],\n",
       "        [0.4431, 0.6496, 0.5671],\n",
       "        [0.4304, 0.6298, 0.5510],\n",
       "        [0.4671, 0.5910, 0.5266],\n",
       "        [0.4177, 0.6503, 0.5645]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_vec = attn_weights @ inputs #context vector is the weighted sum of the input tokens with this attention weights\n",
    "context_vec #each row of the context vector of that token "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15ab57ab",
   "metadata": {},
   "source": [
    "**Implementing self attention with trainable weights**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a63b383",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
